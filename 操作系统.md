[TOC]

---

## 第一章 操作系统概论

#### 操作系统的功能和特性
1. 功能：
    - 处理器管理
        - 目的：提高处理器的利用率
        - 对处理器的管理和调度归结于对进程和线程的管理和调
    - 存储管理
        - 目的：管理内存资源，支撑多道程序的运行，提高存储空间利用率；
        - 内存分配和回收、地址转换与存储保护、内存共享与存储扩充
    - 设备管理
        - 目的：管理各种外部设备，完成 I/O 请求；加快数据传输速度，发挥设备并行性，提高设备利用率； 
    - 文件管理
        - 对象：针对信息资源进行管理 
    - 联网与通信管理
2. 特性：
    - （1）并发性：
    - （2）共享性：指计算机系统中的资源可以被多个并发执行的程序共同使用，而不是被某个程序独占
        1. 透明资源共享
        2. 独占资源共享
    - （3）异步性/随机性：在多道程序环境里允许多个程序并发执行，并发活动会导致随机事件的发生，由于资源有限而程序众多，每个程序的执行都是不连贯的。


#### 多道程序设计
1. 概念：允许多个作业（程序+数据+作业说明书）同时进入计算机系统的内存并启动交替算法的方法。
2. 优点：
    - 提高CPU、内存和设备之间的利用率；
    - 提高系统的吞吐率，使单位时间内完成的作业数量增加；
    - 充分发挥操作系统的并行性，使设备与设备之间、CPU与设备之间均可以并行工作。
3. 缺点：
    - 延长了作业的周转时间。
4. 并行和并发的区别：
    - 并发性：指两个或者两个以上的活动或者事件在同一 **时间间隔**内发生，多个程序并发执行时宏观上的概念，从微观上看，他们是顺序执行的。
    - 并行性：指两个或者两个以上的活动在 **同一时刻** 发生。
    - 并发是指宏观上在一段时间内可以同时运行统一程序，而并行则指在同一时刻能运行多个指令，并行需要硬件支持，如流水线或者多处理器。
    - 并行活动一定是并发的，并发活动不一定是并行的。
5. 计算CPU利用率
    - 假设程序的平均等待 I/O 操作的时间占其运行时间的比例为 p，当内存中有 n 道程序时，所有程序都等待 I/O 操作的概率是 $p^n$，则此时CPU是空闲的，那么 $cpu=1-p^n$

#### 批处理操作系统
1. 作业：把程序、数据连同作业说明书组织起来的任务单位
2. 优缺点：
    - 优点：批处理操作系统根据预先设定的调度策略选择若干作业并发地执行，系统资源利用率高，作业吞吐量大

    - 缺点：作业周转时间延长，不具备交互式计算能力，不利于程序的开发和调试

#### 分时操作系统
1. 实现思路：
    - 多个联机用户同时使用一个计算机系统在各自的终端上进行交互式会话，程序、数据和命令均在会话过程中提供，以问答方式控制程序运行
2. 特点：
    - 同时性
    - 独立性
    - 及时性
    - 交互性

#### 实时操作系统
1. 概念：当外部事件或者数据产生时，能够对其予以接收并以足够快的速度进行处理，所得的结果能够在规定的时间内控制生产过程或对控制对象做出快速响应，并控制所有实时任务协调运行
2. 特点：及时响应、高可靠性

#### 程序接口与系统调用
1. 系统调用：应用程序不能直接访问内核数据，当要获得系统服务时，必须利用系统调用（系统提供给用户的特殊接口）
2. 系统调用作用：
    - 内核可以基于权限和规则对资源访问进行裁决，保证系统的安全性
    - 系统调用对资源进行抽象，提供一致性接口，避免用户在使用资源时发生错误，且是编程效率提高。
3. API 、库函数和系统调用
    - API ：应用程序给不同平台提供相同的应用程序接口
4. 系统调用分类
    - 进程管理
    - 文件管理
    - 设备管理
    - 存储管理
    - 进程管理
    - 信息维护
5. 系统调用实现
    - 操作系统实现系统调用功能的机制称为陷阱或异常处理机制


#### 操作系统内核
1. 概念：内核是一组**程序模块**，作为可信软件来支持进程并发执行的基本功能和基本操作，通常驻留在内核空间，运行与内核态。
2. 提供功能：
    - 中断处理
    - 时钟管理
    - 短程调度：分配处理器，按照一定策略管理处理器的转让，以及完成保护和恢复现场工作。
    - 原语管理：
        - **原语**：内核中不可中断的过程。

---


## 第二章 处理器管理

#### 处理器状态
1. 特权指令和非特权指令
    - 特权指令：仅在内核态才能使用的指令，这些指令涉及改变机器状态、修改寄存器内容、启动设备IO等。操作系统能够执行全部的机器指令
    - 非特权指令：在目态和管态都能工作。应用程序只能使用非特权指令
2. 处理器从用户态装向内核态：
    - 程序请求操作系统服务，执行系统调用
    - 程序运行时产生中断事件（如I/O操作完成），运行程序被中断，转向中断处理程序处理
    - 程序运行时产生异常事件


#### 中断技术
1. 概念：在应用程序执行过程中遇到急需处理的事件时，暂时中止现行程序在CPU上的运行，转而执行相应的事件处理程序，带处理完成后在返回断点或调度其他程序执行的过程。
2. 中断源分类：由硬件发出或产生的中断为**硬中断**
    - 外中断（又称中断或异步中断）：来自处理器之外的中断信号，包括时钟中断、键盘中断、它机中断、外部设备中断
    - 内中断（又称异常或同步中断）：来自处理器内部的信号


#### 进程及其实现
1. 定义：
    - 在多道系统出现后，为刻画系统内部动态状况、描述运行程序活动规律而引进的新概念，所有多道系统都建立在进程的基础上。
    - 从原理角度：是支持程序执行的一种系统机制，对处理器上运行程序的活动规律进行抽象；
    - 从实现角度：是一种数据结构，用来准确刻画运行程序的状态和系统动态变化状况。
2. 引入进程的目的：
     - 刻画程序的并发性
     - 解决资源的共享性
3. 进程具有的属性：
    - 动态性
    - 共享性
    - 独立性
    - 制约性
    - 并发性
4. 进程的三态模型
    - 运行态：进程占用处理器正在运行的状态；
    - 就绪态：进程具备运行条件，等待系统分配处理器以便运行的状态；
    - 等待态：又称阻塞态或睡眠态，进程不具备运行条件，正在等待某个事件完成的状态。


#### 线程及其实现
1. 引入多线程的动机：引入进程的目的是为了使多个程序并发执行，改善资源利用率和提高系统效率，引入多线程是为了**减少程序并发执行时付出的时空开销**
2. 优点：
    - 快速线程切换：统一进程中的多线程切换只需要改变堆栈和寄存器，地址空间不变。
    - 通信易于实现：自动共享进程的内存和文件，线程可以自由的访问全局数据，实现数据共享方便，线程通信简单不必经过内核；
    - 减少管理开销；
    - 并发程度提高。


#### 处理器调度
1. 处理器调度层次
    - 高级调度
    - 中级调度
    - 低级调度：操作系统最核心部分，执行十分频繁，调度对象是内核级线程
        - 剥夺式：当进程/线程正在处理器上运行时，系统可以根据规定的原则剥夺分配给此进程/线程的处理器，并将其移入就绪队列，选择其他进程/线程运行。
        - 非剥夺式：一旦某个进程/线程开始运行后便不再让出处理器，除非此进程/线程运行结束或主动放弃处理器，或发生某个事件不能继续执行。
2. 计算周转时间
    - 周转时间：批处理用户从向系统提交作业开始到完成作业为止称为作业周转时间，批处理系统的调度性能用作业周转时间和带权作业周转时间来衡量，时间越短，系统效率越高，作业吞吐量越大。

    - 如果作业  $i$ 提交给系统的时刻是  $t_s$ ，完成时刻是 $t_f$，那么作业 $i$ 的周转时间  $t_i = t_f - t_s$，实际上，这是作业在系统中等待时间和运行时间之和

    - 平均作业周转时间  $T$ 为 

      ==$$T=(\sum_{i=1}^nt_i)/n$$==

    - 平均周转时间：如果作业  $i$ 的周转时间为  $t_k$ ，则称 $w_i = t_i/t_k$ 为此作业的带权周转时间，平均带权周转时间  $W$ 为

      ==$$W = (\sum_{i=1}^nw_i)/n$$==

#### 作业调度算法
- 挑选作业进入系统**内存**，执行作业需要依赖进程调度
1. ##### 先来先服务算法（First Come First Served,FCFS）
    - 按照作业进入系统后备队列的**先后次序**来挑选作业，先进入系统的作业将被优先挑选进内存，创建用户进程，分配所需资源，再移入就绪队列。**非剥夺式算法**。
    - 
        | 作业名 | 所需CPU时间/ms |
        | ------ | -------------- |
        | 作业1  | 28             |
        | 作业2  | 9              |
        | 作业3  | 3              |
    - 调度顺序，1-2-3，平均作业周转时间 $T=(28+37+40)/3=35ms$，FSFC算法的平均作业周转时间与作业的提交和调度顺序有关。

2. ##### 最短作业优先算法（Shortest Job First,SJF）
    - 以进入系统作业所要求的 **CPU 运行时间的长度**为标准，总是选取预计时间最短的作业投入运行。**非剥夺式算法**。

    - 
        | 作业名 | 所需CPU时间/ms |
        | ------ | -------------- |
        | 作业1  | 9              |
        | 作业2  | 4              |
        | 作业3  | 10             |
        | 作业4  | 8              |

    - 采用SJF算法，调度顺序，2-4-1-3，平均作业周转时间为 $T=(4+12+21+13)/4=17ms$ ，平均带权周转时间为  $w=(4/4+12/8+21/9+31/10)/4=1.98ms$

    - 缺点：需要预先知道作业运行时间，否则调度没有依据

3. ##### 最短剩余时间算法（Shortest Remaining Time First,SRTF）
    - 将 SJF 改造成**剥夺式调度算法**，在就绪队列的新进程/线程所需CPU运行时间比当前运行的进程/线程所需CPU时间短，则执行新进程/线程。
    - 
        | 进程 | 到达系统时间 | 所需CPU时间/ms |
        | :--: | :----------: | :------------: |
        |  P1  |      0       |       8        |
        |  P2  |      1       |       4        |
        |  p3  |      2       |       9        |
        |  p4  |      3       |       5        |
    - P1 从 0 开始执行，p2 在时间 1 到达，而进程 p1 的剩余时间（7ms）大于 p2 所需CPU时间（4ms），所以 p1 的控制权被剥夺，p2 被调度执行
    - 
        | P1   | P2   | P4   | P1   | p3   | null |
        | :--- | :--- | :--- | :--- | :--- | :--- |
        | 0    | 1    | 5    | 10   | 17   | 26   |
    - 平均等待时间 $=((10-1)+(1-1)+(17-2)+(5-3))/4=6.5ms$
    - 平均周转时间 $=((17-0)+(5-1)+(26-2)+(10-3))/4=13ms$
4. ##### 最高响应时间算法(Highest Response Ratio First,HRRF)
    - 响应比：1+作业等待时间/作业处理时间 
5. ##### 优先级调度算法
    - 根据确定的优先级来选取进程/线程，总是选择就绪队列中优先级最高者投入运行。可以预先确定策略为非剥夺或剥夺。
6. 轮转调度算法（Round-Robin，RR）
    - 也称为时间片调度，调度程序每次把 CPU 分配给就绪队列列首进程/线程使用规定的时间间隔，称为时间片，就绪队列中每个进程/线程轮流运行一个时间片，当时间片耗尽就强迫让出处理器，排列到队列的列尾等候下一轮调度。
7. 多级反馈队列调度算法

---



## 第三章 同步、通信和死锁

#### 并发进程
1. 进程的交互：
    - 竞争关系：
        - 死锁问题：一组进程因争夺资源陷入永远等待的状态
        - 饥饿问题：一个可运行进程由于其他进程总是优先于他，而被调度程序无限期的拖延而不能执行。
        - 进程互斥：指若干进程因相互争夺独占型资源而产生的竞争制约关系
    - 协作关系
        - 进程同步：指为完成共同任务的并发进程基于某个条件来协调其活动，因为需要在某些位置上排定执行的先后次序而等待、传递信号或消息所产生的协作制约关系


#### 临界区管理
1. 互斥和临界区
    - 临界区：并发进程中与共享变量有关的程序段称为临界区，共享变量所代表的资源称为临界资源
    - 调度原则：互斥使用，有空让进；忙则要等，有限等待；择一而入，算法可行

####  信号量与PV操作
1. 同步机制：操作系统实现线程同步的机制
2. 信号量与PV操作
    - 一般信号量：设 s 是一个记录型数据结构，value为整型变量，系统初始化时为其赋值；list 是等待使用此类资源的头指针，初始状态为空，记录型信号量如下
    ```
    typedef struct semaphore{
        int value;          /*信号量值*/
        struct pcb* list;  /*信号量队列指针*/
    }
    ```
    - P 操作定义：请求一个资源
    ```c
    void P(semaphore s){
        s.value--;          /*信号量值减 1*/
        /*若信号量小于 0，执行 P 操作的进程调用 sleep(s.list) 阻塞自己，被置成等待信号量 s 状态，并移入 s 信号量队列，转向进程调度程序*/
        if(s.value < 0)     
            sleep(s.list);
    }
    ```
    - V 操作定义：释放一个资源
    ```c
    void V(semaphore s){
        s.value++;          /*信号量值减 1*/
        /*若信号量小于等于 0，则调用 wakeup(s.list) 从信号量 s 队列中释放一个等待信号量 s 的进程并转换为就绪态*/
        if(s.value <= 0)     
            wakeup(s.list);
    }
    ```
    - PV操作都是原语，执行中不能被打断，进程从队列中移出的次序应遵循 FCFS 算法，在 PV 操作之间的代码段是临界区

3. 信号量解决生产者-消费者问题
    - 问题描述：有 n 个生产者和 m 个消费者，连接在有 k 个单位缓冲区的有界环状缓冲上，其中，pi 和 cj 都是并发进程，只要缓冲区未满，生产者进程 pi 产生的产品就可以投入缓冲区；只要缓冲区非空，消费者 cj 就可以从缓冲区取走并消费产品
    - **单缓冲区生产者-消费者问题**：设置两个信号量 empty 和 full，其初值分别为 1 和 0， empty 表示能否向缓冲区放入产品，full 指示能否从缓冲区取出产品
    ```c
    /*单缓冲区生产者-消费者问题*/
    int B;
    semaphore empty;    /*可用的空缓冲区数*/
    semaphore full;     /*缓冲区内可用的产品数*/
    empty = 1;          /*缓冲区内允许放入一件产品*/
    full = 0;           /*缓冲区内没有产品*/
    cobegin
        process producer(){
            while(true){
                produce();
                P(empty);
                append to B;
                V(full);
            }
        }
        process consumer(){
            while(true){
                P(full);
                take from B;
                V(empty);
                consue();
            }
        }
    coend
    ```
    - **m 个生产者和 n 个消费者共享 k 件产品缓冲区问题：**使用一个信号量 mutex（初值为 1）来限制生产者和消费者互斥的对缓冲区进行存取，另用两个信号量 empty（初值为 k）和 full（初值为 0）来保证生产者不向已满的缓冲区放入产品，消费者不向已空的缓冲区取出产品
    ```c
    /*m 个生产者和 n 个消费者共享 k 件产品缓冲区问题*/
    int B[k];
    semaphore empty; empty = k;     /*可用的空缓冲区*/
    semaphore full; full = 0;       /*缓冲区内可用的产品*/
    semaphore mutex; mutex = 1;     /*互斥信号*/
    int in = 0;                     /*放入缓冲区的指针*/
    int out = 0;                    /*取出缓冲区的指针*/
    cobegin
        process produceer_i(){
            while(true){
                produce();
                P(empty);
                P(mutex);
                append to B[in];
                in = (in + 1) % k;
                V(mutex);
                V(full);
            }
        }
        process consumer_j(){
            while(true){
                P(full);
                P(mutex);
                take from B[out];
                out = (out + 1) % k;
                V(mutex);
                V(empty);
                consume();
            }
        }
    coend
    ```
4. 管程
    - 基本思路：把分散在各进程中的临界区集中起来管理，并把抽象资源用数据结构抽象地表示，由于临界区是访问共享资源的代码段，建立一个管理程序来管理访问

5. 死锁
    - 定义：如果一个进程集合中的每个进程都在等待只能由此集合中的其他进程才能引发的事件，无限期的陷入僵持的局面
    - 死锁防止：
        - 产生条件：
            - 互斥条件
            - 占有和等待条件
            - 不剥夺条件
            - 循环等待条件
    - 死锁避免：银行家算法（资源分配拒绝法）
    - 描述：系统中所有的进程放入进程集合，在安全状态下系统接收到进程的资源请求后，先把资源试探性的分配给它，然后系统将剩下的可用资源和进程集合中的其他进程还需要的资源数做比较，找出剩余资源能满足最大需求量的进程，从而保证进程运行完毕并归还全部资源；这时把这个进程从进程集合中删除，归还其所占用的所有资源，系统剩余资源则更多；反复执行，最后检查进程集合，若为空表示本次申请可行，实施分配；

---

## 第四章 存储管理

#### 存储管理
1. 包括功能
    - 存储分配
    - 地址映射
    - 存储保护
    - 存储共享
    - 存储扩充

#### 存储器工作原理
1. 源程序在计算机上的三个处理过程
    - 程序编译：源程序经过编译程序或汇编程序的处理生成目标模块（目标代码）
    - 程序链接：根据目标某块之间的调用和依赖关系，将主调模块、被掉模块以及所用到的库函数装配和链接成一个完整的可装载执行模块
        - 静态链接
        - 动态链接
        - 运行时链接
    - 程序装载：装载程序把可执行程序装入内存
        - 绝对装载
        - 可重定位装载
        - 动态运行时装载

#### 固定分区管理
1. 思想：内存空间被划分成数目固定不变的分区，各分区大小不等，每个分区只装入一个作业，若多个分区中都装有作业，则它们可以并发执行

#### 可变分区管理
1. 动态创建分区：在装入程序时按其初始要求分配，或在其执行过程中通过系统调用进行分配或改变分区大小
    - 优点：没有内碎片
    - 缺点：有外部碎片
2. 数据结构的管理
    - 已分配区表和未分配区表
3. 分区分配算法
    - 概念：寻找某个空闲分区，其大小需大于或等于程序的要求。若是大于要求，则将该分区分割成两个分区，其中一个分区为要求大小并标记为“占用”，而另一个分区为余下部分并标记为“空闲”。分区的先后次序通常是从内存低端到高端。
    - **首次适应法（first-fit）**
        1. 按分区的先后次序，从头查找，找到符合要求的第一个分区
        2. 该算法的分配和释放的时间性能较好，较大的空闲分区可以保存在内存高端
        3. 低端分区不断划分产生较多小分区，每次分配时查找时间开销会增大
    - **下次适应法（next-fit）**
        1. 按分区的先后次序，从上次分配的分区起开始查起（到最后分区再回到开头），找到符合要求的第一个分区
        2. 该算法的分配和释放的时间性能较好，使空闲分区分布得更均匀，但是较大的空闲分区不易保留
    - **最佳适应法（best-fit）**
        1. 找到其大小与要求相差最小的空闲分区
        2. 从个别来看，外碎片较小，但是从整体来看，会形成较多外碎片。较大的空闲分区可以被保留。
    - **最坏适应法（worst-fit）**
        1. 找到最大的空闲分区
        2. 基本不留下小空闲区，但较大的空闲分区不被保留

4. 分区释放算法：
    - 需要将相邻的空闲分区合并成一个空闲分区。（需要解决问题：合并条件的判断和合并时机的选择）

5. 分页存储管理
    - 页面：进程逻辑地址空间分成大小相等的区，每个区称为页面或者页，页号从 0 开始编号
    - 逻辑地址：由页号和页内位移两部分组成
    - 
    - 物理地址 = 页框号 * 块长 + 页内位移
6. 缺页中断
    - 在地址映射过程中，在页表中发现所要访问的页不在内存，则产生缺页中断。操作系统接到此中断信号后，就调出缺页中断处理程序，根据页表中给出的外存地址，将该页调入内存，使进程继续运行下去

7. 页面淘汰算法
    - 功能：需要调入页面时，选择哪个物理页面被置换
    - 目标：把未来不再使用的或短期内较少使用的页面调出，通常只能在局部性原理指导下依据过去的统计数据预测
    - **先进先出算法（FIFO）**
        1. 总是淘汰最先进入主存储器的那一页，可以通过链表来表示各页建立时间的先后。性能较差。
        2. Belady现象：采用FIFO算法时，如果对一个进程未分配他所要求的全部页面，有时会出现分配的页面数增多，缺页率反而提高的异常现象。
        3. 出现 Belady 现象的原因：FIFO 算法的置换特征与进程访问内存的动态特征是矛盾的，即被置换的页面并不是进程不会访问的
    - **最久未使用淘汰算法（LRU算法）**
        1. 实质：当需要淘汰一页时，选择最长时间未使用的页
        2. 依据：如果某页被访问，可能马上还要被访问，如果某页长时间未被访问，最近也不可能被访问
        3. 算法实现：设置一个活动页面栈，当访问某页时，将此页**压入栈顶**，再考虑栈内是否有与此页面相同的页号，有则抽出。淘汰一页时，总是从**栈底抽出**一个页号，他就是最久未使用的
    - **最不常用算法（LFU算法）**
        1. 选择到当前时间为止被访问次数最少的页面被置换
        2. 每页设置访问计数器，每当页面被访问时，该页面的访问计数器加 1
        3. 发生缺页中断时，淘汰计数值最小的页面，并将所有计数清零
    - **最佳算法（OPT算法）**
        1. 选择“未来不再使用的”或者“在离当前最远位置上出现的”页面被置换。

---

## 第五章 设备管理

#### I/O控制方式
1. 轮询方式
2. 中断方式
3. DMA方式
    - 直接存储器存取：设备直接与内存交换数据而不占用CPU，从CPU取得系统总线的控制，大批量处理数据，高效。
4. 通道方式

#### 磁盘调度-优化分布

#### 缓冲技术
1. 目的：解决CPU与设备速度的不匹配，协调逻辑记录大小与物理大小不一致，提高CPU和设备之间的并行性，减少I/O操作对CPU的中断次数
2. 基本思想：当进程执行写操作输出数据时，先向系统申请一个输出缓冲区，然后将数据送至缓冲区

#### 搜查定位
1. **先来先服务算法（FSFC）**
    - 它只考虑对磁盘请求的先后次序，而不考虑访问的物理位置，所有对磁盘有I/O请求的进程先去等待队列中排队，排在先的先给予服务。该算法对于访问进程是平等的，先提I/O请求的进程，磁盘先分给它使用。
      这种算法当访问请求分布不好时，可能会造成磁臂反复来回移动，增加总的访问时间，无法实现查找优化，只适用于访问请求不太多的情况。
2. **最短查找时间优先算法（SSFT）**
    - 它总是选择请求 队列中离当前磁头所在柱面最近的下一个柱面作为即将访问的对象，而不管请求访问者到达请求队列的先后次序。
      此算法克服了FCFS算法中磁臂大幅度来回移动的缺陷，在吞吐量上有所提高。但对访问者的服务机会是不均衡的，有时会造成内／外边缘磁道上的请求被无限推迟响应的现象。
      3.** 扫描算法（SCAN）**
    - 如果磁臂目前向内移动，则下一个访问对象，应该是磁头当前所在柱面以内的那些柱面中，距磁头最近的那个柱面。下一个访问对象仍这样选择，直到该方向上没有更内侧的请求为止。磁头改变方向转向外，边移动边服务，完后又转向内服务，反复扫描访问请求，依次给予服务。此方法与自然界中电梯工作的方式极为相象，故也称“电梯调度”算法。    

#### 提高磁盘 I/O 速度的方法
1. 提前读
2. 延迟写
3. 虚拟盘

#### 设备分配
1. 物理特性分类
    - 独占型设备
    - 共享设备
    - 虚拟设备
2. 相应管理和设备的技术：
    - 静态分配
    - 动态分配
    - 虚拟分配

#### 虚拟设备
1. SPOOLing 技术是用一类物理设备模拟另一类物理设备的技术，是使独占型设备变成共享设备的一种技术。

----

## 第六章 文件管理

#### 文件的存取方法
1. 顺序存取
2. 直接存取，又称随机存取
    - 可以非顺序的从文件中的任何位置存储文件的内容。
3. 索引存取

------

------











